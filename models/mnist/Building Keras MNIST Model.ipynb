{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing dataset and data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1.1. Import of essential libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import tensorflowjs as tfjs\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./input/train.csv\")\n",
    "\n",
    "# Labels\n",
    "Y_train = train[\"label\"]\n",
    "# Features\n",
    "X_train = train.drop(labels = [\"label\"],axis = 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalization\n",
    "X_train = X_train / 255.0\n",
    "\n",
    "# Reshape\n",
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "\n",
    "# Lable encoding\n",
    "Y_train = to_categorical(Y_train, num_classes = 10)\n",
    "\n",
    "# Split into training and valdiation sets\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    X_train, \n",
    "    Y_train, \n",
    "    test_size = 0.1, \n",
    "    random_state=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Define Keras model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model using Keras Sequential API\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "# CONVOLUTIONAL/MAXPOOL LAYERS\n",
    "# = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
    "\n",
    "# Convolutional 2D layer #1\n",
    "# Computes 32 features using a 5x5 filter with ReLU activation.\n",
    "model.add(Conv2D(\n",
    "    filters = 32, \n",
    "    kernel_size = (5,5),\n",
    "    padding = 'Same', \n",
    "    activation ='relu',\n",
    "    input_shape = (28,28,1)\n",
    "))\n",
    "\n",
    "# Convolutional 2D layer #2\n",
    "# Computes 32 features using a 5x5 filter with ReLU activation.\n",
    "model.add(Conv2D(\n",
    "    filters = 32, \n",
    "    kernel_size = (5,5),\n",
    "    padding = 'Same', \n",
    "    activation ='relu'\n",
    "))\n",
    "\n",
    "# Pooling layer #1\n",
    "# Max pooling layer with a 2x2 filter\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "# Dopout operation; 0.75 probability that element will be kept\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Convolutional 2D layer #3\n",
    "# Computes 64 features using a 3x3 filter with ReLU activation.\n",
    "model.add(Conv2D(\n",
    "    filters = 64, \n",
    "    kernel_size = (3,3),\n",
    "    padding = 'Same', \n",
    "    activation ='relu'\n",
    "))\n",
    "\n",
    "# Convolutional 2D layer #4\n",
    "# Computes 64 features using a 3x3 filter with ReLU activation.\n",
    "model.add(Conv2D(\n",
    "    filters = 64, \n",
    "    kernel_size = (3,3),\n",
    "    padding = 'Same', \n",
    "    activation ='relu'\n",
    "))\n",
    "\n",
    "# Pooling layer #1\n",
    "# Max pooling layer with a 2x2 filter and stride of 2\n",
    "model.add(MaxPool2D(\n",
    "    pool_size=(2,2), \n",
    "    strides=(2,2)\n",
    "))\n",
    "\n",
    "# Dopout operation; 0.75 probability that element will be kept\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Flatten layer \n",
    "# Convert Tensor into a one single 1D vector\n",
    "model.add(Flatten())\n",
    "\n",
    " \n",
    "# FULLY CONNECTED LAYERS\n",
    "# = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = \n",
    "\n",
    "# Danse layer #1\n",
    "# Densely connected layer with 256 units\n",
    "model.add(Dense(\n",
    "    256, \n",
    "    activation = \"relu\"\n",
    "))\n",
    "\n",
    "# Dopout operation; 0.5 probability that element will be kept\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Danse layer #2\n",
    "# Densely connected layer with 10 units\n",
    "model.add(Dense(\n",
    "    10, \n",
    "    activation = \"softmax\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Set the optimizer and annealer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimizer function will iteratively improve parameters\n",
    "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Learning rate annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(\n",
    "    monitor='val_acc', \n",
    "    patience=3, \n",
    "    verbose=1, \n",
    "    factor=0.5, \n",
    "    min_lr=0.00001\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    rotation_range=10,\n",
    "    zoom_range = 0.1,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False\n",
    ")\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " - 127s - loss: 0.5052 - acc: 0.8365 - val_loss: 0.0849 - val_acc: 0.9729\n",
      "Epoch 2/30\n",
      " - 127s - loss: 0.1512 - acc: 0.9549 - val_loss: 0.0473 - val_acc: 0.9864\n",
      "Epoch 3/30\n",
      " - 127s - loss: 0.1129 - acc: 0.9660 - val_loss: 0.0409 - val_acc: 0.9864\n",
      "Epoch 4/30\n",
      " - 127s - loss: 0.0913 - acc: 0.9722 - val_loss: 0.0401 - val_acc: 0.9898\n",
      "Epoch 5/30\n",
      " - 127s - loss: 0.0807 - acc: 0.9759 - val_loss: 0.0282 - val_acc: 0.9907\n",
      "Epoch 6/30\n",
      " - 127s - loss: 0.0740 - acc: 0.9783 - val_loss: 0.0370 - val_acc: 0.9895\n",
      "Epoch 7/30\n",
      " - 127s - loss: 0.0728 - acc: 0.9794 - val_loss: 0.0337 - val_acc: 0.9890\n",
      "Epoch 8/30\n",
      " - 127s - loss: 0.0671 - acc: 0.9804 - val_loss: 0.0554 - val_acc: 0.9826\n",
      "Epoch 9/30\n",
      " - 127s - loss: 0.0651 - acc: 0.9816 - val_loss: 0.0419 - val_acc: 0.9917\n",
      "Epoch 10/30\n",
      " - 127s - loss: 0.0647 - acc: 0.9815 - val_loss: 0.0250 - val_acc: 0.9929\n",
      "Epoch 11/30\n",
      " - 127s - loss: 0.0714 - acc: 0.9800 - val_loss: 0.0227 - val_acc: 0.9921\n",
      "Epoch 12/30\n",
      " - 127s - loss: 0.0680 - acc: 0.9821 - val_loss: 0.0312 - val_acc: 0.9898\n",
      "Epoch 13/30\n",
      " - 127s - loss: 0.0718 - acc: 0.9804 - val_loss: 0.0238 - val_acc: 0.9924\n",
      "Epoch 14/30\n",
      " - 127s - loss: 0.0742 - acc: 0.9805 - val_loss: 0.0288 - val_acc: 0.9907\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 15/30\n",
      " - 127s - loss: 0.0551 - acc: 0.9849 - val_loss: 0.0216 - val_acc: 0.9940\n",
      "Epoch 16/30\n",
      " - 127s - loss: 0.0537 - acc: 0.9860 - val_loss: 0.0296 - val_acc: 0.9921\n",
      "Epoch 17/30\n",
      " - 126s - loss: 0.0558 - acc: 0.9855 - val_loss: 0.0269 - val_acc: 0.9907\n",
      "Epoch 18/30\n",
      " - 126s - loss: 0.0516 - acc: 0.9867 - val_loss: 0.0198 - val_acc: 0.9933\n",
      "Epoch 19/30\n",
      " - 127s - loss: 0.0511 - acc: 0.9863 - val_loss: 0.0322 - val_acc: 0.9917\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 20/30\n",
      " - 126s - loss: 0.0469 - acc: 0.9880 - val_loss: 0.0241 - val_acc: 0.9933\n",
      "Epoch 21/30\n",
      " - 126s - loss: 0.0449 - acc: 0.9882 - val_loss: 0.0184 - val_acc: 0.9940\n",
      "Epoch 22/30\n",
      " - 126s - loss: 0.0424 - acc: 0.9878 - val_loss: 0.0203 - val_acc: 0.9950\n",
      "Epoch 23/30\n",
      " - 126s - loss: 0.0442 - acc: 0.9888 - val_loss: 0.0230 - val_acc: 0.9924\n",
      "Epoch 24/30\n",
      " - 127s - loss: 0.0427 - acc: 0.9880 - val_loss: 0.0223 - val_acc: 0.9936\n",
      "Epoch 25/30\n",
      " - 127s - loss: 0.0396 - acc: 0.9886 - val_loss: 0.0187 - val_acc: 0.9936\n",
      "Epoch 26/30\n",
      " - 127s - loss: 0.0439 - acc: 0.9883 - val_loss: 0.0201 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 27/30\n",
      " - 127s - loss: 0.0408 - acc: 0.9891 - val_loss: 0.0194 - val_acc: 0.9938\n",
      "Epoch 28/30\n",
      " - 127s - loss: 0.0400 - acc: 0.9892 - val_loss: 0.0238 - val_acc: 0.9948\n",
      "Epoch 29/30\n",
      " - 127s - loss: 0.0392 - acc: 0.9894 - val_loss: 0.0209 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 30/30\n",
      " - 127s - loss: 0.0403 - acc: 0.9890 - val_loss: 0.0185 - val_acc: 0.9948\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "    epochs = epochs, \n",
    "    validation_data = (X_val,Y_val),\n",
    "    verbose = 2, \n",
    "    steps_per_epoch=X_train.shape[0] // batch_size, \n",
    "    callbacks=[learning_rate_reduction]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# Save Python model\n",
    "model.save('ModelPY/model.h5')\n",
    "# Save JS model\n",
    "tfjs.converters.save_keras_model(model, './ModelJS')\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. More of useful information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Introduction to CNN Keras - 0.997 (top 6%) by Yassine Ghouzam][1]\n",
    "\n",
    "[1]: https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6/code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
